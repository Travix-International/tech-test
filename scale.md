# Scale

This part based on my assumption no 7 because of there is lot to talk about it like that, you can check my concern about it from question 6.

1- External firewall : place it before checking request for the prevention of possible ddos attacks, it seems like nothing to do with scaling at first but this can be a possible threat day by day when our request limits grows.

2- Load balancer with reverse proxy : It's reverse proxy part will keep the resources ip's hidden and compressing the response from our servers. Load balancer part will handle the share request load within our servers. Possible products can be used : Netscaler

3- Web Servers with failovers : we will store our entire web application and api implementation in these servers. Our configuration based on docker virtualization, so both vertical and horizontal scale on this area will be quick. In the case of fail, the failover server will handle the request, all we have to do is monitor the situtation and remove away the failed server from the farm. Possible products can be used : no forced technologies in both web app and api side. we can use a broad range from c# to node.js as long as docker supports it. One constraint for this part may be a micro services instead of one big monolith service for distribute the api load but in this scenario we have very few operations, so this might be an overengineering. Also operating systems are does not matter, but can be discussed for the better performance (out of scope currently).

4- Cache Servers with failovers : In we think about our scenario, we have not much of a complexity in our load( eg : CMS, CRM systems or real time apps) but it requires very fast response time and concurrency. With these requirements i prefer to use amazon's in memory caching solution DynamoDB Accelerator(Dax). Because it's very reliable on read-heavy operations and can handle the request very quickly. But if we look at the other side, it is not a very mature product like it's competitors, and ties us to a cloud platform partly. So a product like Redis can do the trick in this part with keeping our requirements. Failover mechanism will be the same as web servers but also we will need a replication to keep the instances same.

5- Database Servers with failovers : Within our scenario, as i mentioned in cache servers we need low latency and high concurrency, and if we think about our data's complexity to be stored in the database, i could not see any reason to use rdbms solution. I prefer to use Couchbase to keep db-related things minimum, just store it, give me quickly when i want and have persistency. there is a concern for this part that i mentioned in question 5, but if we look at the overall(performance, fast response) couchbase can give us what we want for bigger request counts. It's scalability is also good, so we can go horizontal or vertical scaling with minimum down time. Failover mechanism will be the same as web and cache servers but also we will need a replication to keep the instances same.